{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "!pip install texthero"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting texthero\n",
      "  Downloading texthero-1.1.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: tqdm>=4.3 in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from texthero) (4.64.0)\n",
      "Collecting spacy<3.0.0\n",
      "  Downloading spacy-2.3.9-cp39-cp39-win_amd64.whl (9.1 MB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from texthero) (1.21.5)\n",
      "Requirement already satisfied: plotly>=4.2.0 in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from texthero) (5.5.0)\n",
      "Collecting gensim<4.0,>=3.6.0\n",
      "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
      "Requirement already satisfied: pandas>=1.0.2 in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from texthero) (1.3.5)\n",
      "Requirement already satisfied: matplotlib>=3.1.0 in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from texthero) (3.5.1)\n",
      "Collecting nltk>=3.3\n",
      "  Downloading nltk-3.8-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from texthero) (1.0.2)\n",
      "Collecting unidecode>=1.1.1\n",
      "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
      "Collecting wordcloud>=1.5.0\n",
      "  Downloading wordcloud-1.8.2.2-cp39-cp39-win_amd64.whl (153 kB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from gensim<4.0,>=3.6.0->texthero) (1.7.3)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from gensim<4.0,>=3.6.0->texthero) (1.16.0)\n",
      "Collecting smart_open>=1.8.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (4.28.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (21.3)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from nltk>=3.3->texthero) (1.1.0)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.10.31-cp39-cp39-win_amd64.whl (267 kB)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from nltk>=3.3->texthero) (8.0.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\envs\\pythonproject\\lib\\site-packages (from pandas>=1.0.2->texthero) (2021.3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os\r\n",
    "from typing import Dict\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import tensorflow_datasets as tfds\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.models import model_from_json\r\n",
    "\r\n",
    "import texthero as hero\r\n",
    "\r\n",
    "from texthero import stopwords\r\n",
    "\r\n",
    "from nltk.corpus import stopwords"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "input_file = 'D:\\\\repos\\\\ml_crash_course\\\\data\\\\labeled_data_corpus.csv'\r\n",
    "if not os.path.exists(input_file):\r\n",
    "    raise RuntimeError(f'No input file: {input_file}')\r\n",
    "\r\n",
    "df = pd.read_csv(input_file)\r\n",
    "train_df = df[df['subset'] == 'train']\r\n",
    "test_df = df[df['subset'] == 'test']\r\n",
    "print('num rows for train: %d', train_df.shape[0])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num rows for train: %d 5233\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "X_train = train_df['msg']\r\n",
    "y_train = train_df['label']\r\n",
    "\r\n",
    "X_test = test_df['msg']\r\n",
    "y_test = test_df['label']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "X_train[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    здравствуйте. ишу 2х спальную квартиру в лимас...\n",
       "1    #сниму  комнату в лимассоле или недалеко от не...\n",
       "2                        мошенник риэлторским услугам.\n",
       "3    **sales**    reg.1053 lic.489/e **stylish apar...\n",
       "4    важно: [valerii korol](tg://user?id=193474890)...\n",
       "5    аренда  no: 367/e ️ларнака️между пила и декели...\n",
       "6    привет  ищу виллу посуточно с бюджетом 2000€ в...\n",
       "7    важно: [liss](tg://user?id=202814885), если ты...\n",
       "8                               total messages: 126772\n",
       "9    аренда  ️ларнака ️в центре города️ saint lazar...\n",
       "Name: msg, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "X_train = X_train.str.lower()\r\n",
    "X_train = X_train.dropna()\r\n",
    "\r\n",
    "X_train = hero.remove_digits(X_train)\r\n",
    "X_train = hero.remove_punctuation(X_train)\r\n",
    "X_train = hero.remove_stopwords(X_train)\r\n",
    "X_train = hero.remove_whitespace(X_train)\r\n",
    "\r\n",
    "russian_stopwords = stopwords.words(\"russian\")\r\n",
    "X_train = hero.remove_stopwords(X_train, russian_stopwords)\r\n",
    "\r\n",
    "greek_stopwords = stopwords.words(\"greek\")\r\n",
    "X_train = hero.remove_stopwords(X_train, greek_stopwords)\r\n",
    "\r\n",
    "turkish_stopwords = stopwords.words(\"turkish\")\r\n",
    "X_train = hero.remove_stopwords(X_train, turkish_stopwords)\r\n",
    "\r\n",
    "X_train = hero.remove_whitespace(X_train)\r\n",
    "\r\n",
    "#only utf8 allowed\r\n",
    "X_train = X_train.map(lambda x: bytes(x, 'utf-8').decode('utf-8', 'ignore'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "X_train[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    здравствуйте ишу 2х спальную квартиру лимассол...\n",
       "1    сниму комнату лимассоле недалеко начала август...\n",
       "2                         мошенник риэлторским услугам\n",
       "3    sales reg lic e stylish apartment sea view kis...\n",
       "4    важно valerii korol tg user id бот спамер прой...\n",
       "5    аренда e ларнакамежду пила декелия пешей досту...\n",
       "6    привет ищу виллу посуточно бюджетом сутки дней...\n",
       "7    важно liss tg user id бот спамер пройди провер...\n",
       "8                                       total messages\n",
       "9    аренда ларнака центре города saint lazaro chur...\n",
       "Name: msg, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "unique_words = list(X_train.str.split(' ', expand=True).stack().unique())\r\n",
    "len(unique_words)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "14795"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "a = X_train.apply(lambda x: len(x.split(\" \")))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "a.sum() / len(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "34.68087139308236"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "X_test = X_test.str.lower()\r\n",
    "X_test = X_test.dropna()\r\n",
    "\r\n",
    "X_test = hero.remove_digits(X_test)\r\n",
    "X_test = hero.remove_punctuation(X_test)\r\n",
    "X_test = hero.remove_stopwords(X_test)\r\n",
    "X_test = hero.remove_whitespace(X_test)\r\n",
    "\r\n",
    "russian_stopwords = stopwords.words(\"russian\")\r\n",
    "X_test = hero.remove_stopwords(X_test, russian_stopwords)\r\n",
    "\r\n",
    "greek_stopwords = stopwords.words(\"greek\")\r\n",
    "X_test = hero.remove_stopwords(X_test, greek_stopwords)\r\n",
    "\r\n",
    "turkish_stopwords = stopwords.words(\"turkish\")\r\n",
    "X_test = hero.remove_stopwords(X_test, turkish_stopwords)\r\n",
    "\r\n",
    "X_test = hero.remove_whitespace(X_test)\r\n",
    "\r\n",
    "#only utf8 allowed\r\n",
    "X_test = X_test.map(lambda x: bytes(x, 'utf-8').decode('utf-8', 'ignore'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "X_test[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5233    сдам собственник лимассол сдаю комнатную новую...\n",
       "5234    важно tiana tg user id бот спамер пройди прове...\n",
       "5235    привет алена tg user id это бесплатная группа ...\n",
       "5236    привет meds tg user id это бесплатная группа а...\n",
       "5237    аренда район линопетра лимассол долгосрочную а...\n",
       "5238                                     клиент приезжает\n",
       "5239                    james michael tg user id забанили\n",
       "5240    сдается квартира пафосе район хлорака м2 спаль...\n",
       "5241    аренда х комнатного дома джакузи выходом крышу...\n",
       "5242    квартира спальнями ванной комнатой верандами к...\n",
       "Name: msg, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "X_train = X_train.values\r\n",
    "\r\n",
    "X_test = X_test.values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "len(X_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5233"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "X_train[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'здравствуйте ишу 2х спальную квартиру лимассоле желательно гермасойя семья 2х взрослых 2х детей животных длительный срок бюджет евро предложения лс'"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "VOCAB_SIZE = 14000\r\n",
    "encoder = tf.keras.layers.TextVectorization(\r\n",
    "    max_tokens=VOCAB_SIZE)\r\n",
    "encoder.adapt(X_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\r\n",
    "len(vocab[:])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "14000"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "model = tf.keras.Sequential([\r\n",
    "    tf.keras.Input(shape=(1,), dtype=tf.string),\r\n",
    "    \r\n",
    "    tf.keras.layers.TextVectorization(\r\n",
    "        max_tokens=VOCAB_SIZE,output_mode='int',\r\n",
    "        vocabulary=np.delete(np.delete(vocab, 0),0)),\r\n",
    "    tf.keras.layers.Embedding(\r\n",
    "        input_dim=len(encoder.get_vocabulary()),\r\n",
    "        output_dim=32,\r\n",
    "        # Use masking to handle the variable sequence lengths\r\n",
    "        mask_zero=True),\r\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\r\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\r\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\r\n",
    "])\r\n",
    "\r\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\r\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\r\n",
    "              metrics=[\r\n",
    "      tf.keras.metrics.Precision(name='precision'),\r\n",
    "      tf.keras.metrics.Recall(name='recall')\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_1 (TextV  (None, None)             0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 32)          448000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               16640     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 466,753\n",
      "Trainable params: 466,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "history4 = model.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=20)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "164/164 [==============================] - 16s 61ms/step - loss: 0.6316 - precision: 0.3137 - recall: 0.0153 - val_loss: 0.4993 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/20\n",
      "164/164 [==============================] - 8s 46ms/step - loss: 0.3828 - precision: 0.9667 - recall: 0.1106 - val_loss: 0.2918 - val_precision: 0.9412 - val_recall: 0.4867\n",
      "Epoch 3/20\n",
      "164/164 [==============================] - 8s 47ms/step - loss: 0.2320 - precision: 0.8924 - recall: 0.7350 - val_loss: 0.2282 - val_precision: 0.8577 - val_recall: 0.8023\n",
      "Epoch 4/20\n",
      "164/164 [==============================] - 8s 47ms/step - loss: 0.1679 - precision: 0.8647 - recall: 0.9075 - val_loss: 0.2128 - val_precision: 0.8654 - val_recall: 0.8555\n",
      "Epoch 5/20\n",
      "164/164 [==============================] - 8s 49ms/step - loss: 0.1314 - precision: 0.8754 - recall: 0.9447 - val_loss: 0.2052 - val_precision: 0.8633 - val_recall: 0.8403\n",
      "Epoch 6/20\n",
      "164/164 [==============================] - 8s 47ms/step - loss: 0.1086 - precision: 0.8990 - recall: 0.9504 - val_loss: 0.2107 - val_precision: 0.8706 - val_recall: 0.8441\n",
      "Epoch 7/20\n",
      "164/164 [==============================] - 8s 49ms/step - loss: 0.0922 - precision: 0.9200 - recall: 0.9542 - val_loss: 0.1984 - val_precision: 0.8835 - val_recall: 0.8365\n",
      "Epoch 8/20\n",
      "164/164 [==============================] - 9s 53ms/step - loss: 0.0761 - precision: 0.9385 - recall: 0.9600 - val_loss: 0.2353 - val_precision: 0.9042 - val_recall: 0.8251\n",
      "Epoch 9/20\n",
      "164/164 [==============================] - 9s 56ms/step - loss: 0.0687 - precision: 0.9511 - recall: 0.9647 - val_loss: 0.2207 - val_precision: 0.8975 - val_recall: 0.8327\n",
      "Epoch 10/20\n",
      "164/164 [==============================] - 8s 49ms/step - loss: 0.0591 - precision: 0.9558 - recall: 0.9695 - val_loss: 0.2222 - val_precision: 0.8837 - val_recall: 0.8669\n",
      "Epoch 11/20\n",
      "164/164 [==============================] - 8s 49ms/step - loss: 0.0542 - precision: 0.9586 - recall: 0.9724 - val_loss: 0.2616 - val_precision: 0.9030 - val_recall: 0.8137\n",
      "Epoch 12/20\n",
      "164/164 [==============================] - 8s 47ms/step - loss: 0.0500 - precision: 0.9623 - recall: 0.9743 - val_loss: 0.2186 - val_precision: 0.9000 - val_recall: 0.8213\n",
      "Epoch 13/20\n",
      "164/164 [==============================] - 8s 47ms/step - loss: 0.0416 - precision: 0.9697 - recall: 0.9762 - val_loss: 0.2583 - val_precision: 0.9174 - val_recall: 0.8023\n",
      "Epoch 14/20\n",
      "164/164 [==============================] - 8s 46ms/step - loss: 0.0371 - precision: 0.9725 - recall: 0.9790 - val_loss: 0.2312 - val_precision: 0.8963 - val_recall: 0.8213\n",
      "Epoch 15/20\n",
      "164/164 [==============================] - 7s 45ms/step - loss: 0.0350 - precision: 0.9753 - recall: 0.9800 - val_loss: 0.2293 - val_precision: 0.8774 - val_recall: 0.8707\n",
      "Epoch 16/20\n",
      "164/164 [==============================] - 7s 46ms/step - loss: 0.0334 - precision: 0.9772 - recall: 0.9790 - val_loss: 0.2460 - val_precision: 0.9060 - val_recall: 0.8061\n",
      "Epoch 17/20\n",
      "164/164 [==============================] - 8s 47ms/step - loss: 0.0320 - precision: 0.9799 - recall: 0.9781 - val_loss: 0.2330 - val_precision: 0.8817 - val_recall: 0.8783\n",
      "Epoch 18/20\n",
      "164/164 [==============================] - 7s 45ms/step - loss: 0.0324 - precision: 0.9764 - recall: 0.9857 - val_loss: 0.1921 - val_precision: 0.9068 - val_recall: 0.8137\n",
      "Epoch 19/20\n",
      "164/164 [==============================] - 7s 46ms/step - loss: 0.0276 - precision: 0.9837 - recall: 0.9809 - val_loss: 0.1995 - val_precision: 0.9004 - val_recall: 0.8251\n",
      "Epoch 20/20\n",
      "164/164 [==============================] - 7s 45ms/step - loss: 0.0251 - precision: 0.9810 - recall: 0.9838 - val_loss: 0.1976 - val_precision: 0.8851 - val_recall: 0.8783\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "precision = history4.history['val_precision'][-1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "recall = history4.history['val_recall'][-1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "f1 = (2 * recall * precision) / (recall + precision)\r\n",
    "print(f1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8816793864275645\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# serialize model to JSON\r\n",
    "model_json = model.to_json()\r\n",
    "with open(\"D:\\\\repos\\\\ml_crash_course\\\\data\\\\model.json\", \"w\") as json_file:\r\n",
    "    json_file.write(model_json)\r\n",
    "# serialize weights to tf\r\n",
    "model.save_weights(\"D:\\\\repos\\\\ml_crash_course\\\\data\\\\model\", save_format = 'tf')\r\n",
    "print(\"Saved model to disk\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# load json and create model\r\n",
    "json_file = open(\"D:\\\\repos\\\\ml_crash_course\\\\data\\\\model.json\", 'r')\r\n",
    "loaded_model_json = json_file.read()\r\n",
    "json_file.close()\r\n",
    "loaded_model = model_from_json(loaded_model_json)\r\n",
    "# load weights into new model\r\n",
    "loaded_model.load_weights(\"D:\\\\repos\\\\ml_crash_course\\\\data\\\\model\")\r\n",
    "print(\"Loaded model from disk\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "loaded_model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_1 (TextV  (None, None)             0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 32)          448000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               16640     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 466,753\n",
      "Trainable params: 466,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "def preprocessing(messages : np.ndarray) -> pd.Series:\r\n",
    "    pd_messages = pd.Series(messages)\r\n",
    "    pd_messages = pd_messages.str.lower()\r\n",
    "    pd_messages = pd_messages.dropna()\r\n",
    "\r\n",
    "    pd_messages = hero.remove_digits(pd_messages)\r\n",
    "    pd_messages = hero.remove_punctuation(pd_messages)\r\n",
    "    pd_messages = hero.remove_stopwords(pd_messages)\r\n",
    "    pd_messages = hero.remove_whitespace(pd_messages)\r\n",
    "\r\n",
    "    russian_stopwords = stopwords.words(\"russian\")\r\n",
    "    pd_messages = hero.remove_stopwords(pd_messages, russian_stopwords)\r\n",
    "\r\n",
    "    greek_stopwords = stopwords.words(\"greek\")\r\n",
    "    pd_messages = hero.remove_stopwords(pd_messages, greek_stopwords)\r\n",
    "\r\n",
    "    turkish_stopwords = stopwords.words(\"turkish\")\r\n",
    "    pd_messages = hero.remove_stopwords(pd_messages, turkish_stopwords)\r\n",
    "\r\n",
    "    pd_messages = hero.remove_whitespace(pd_messages)\r\n",
    "\r\n",
    "    return pd_messages"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "msg = '#аренда #квартира  #лимассол #агент.  ппрп: квартира / 1 спальня    абобус -в конце макариос авеню - апостолос андреас  трехэтажный жилой дом, расположенный в тихом, спокойном жилом районе лимассола, в непосредственной близости от центра города, с легким доступом к близлежащим школам, супермаркетам, а также многим другим услугам , новый порт , молл. квартира с 1 спальней  - открытого плана зал совмещен с кухней  душевая комната  и просторная веранда  крытая парковка и кладовая   все здание теплоизолированное с использованием энергосберегающих технологий класса а, а все окна оснащены двойным тепловым остеклением. квартира сдается  без мебели, будет  оборудована электроприборами и установлены кондиционеры. идеальное тихое место в центре города! цена снижена : €1,050 /per month (plus 1 deposit )'\r\n",
    "\r\n",
    "\r\n",
    "print(preprocessing(np.array( [msg] ))[0])\r\n",
    "\r\n",
    "pred = loaded_model.predict(preprocessing(np.array( [msg] )))\r\n",
    "print(pred[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "аренда квартира лимассол агент ппрп квартира спальня абобус конце макариос авеню апостолос андреас трехэтажный жилой дом расположенный тихом спокойном жилом районе лимассола непосредственной близости центра города легким доступом близлежащим школам супермаркетам также многим другим услугам новый порт молл квартира спальней открытого плана зал совмещен кухней душевая комната просторная веранда крытая парковка кладовая здание теплоизолированное использованием энергосберегающих технологий класса окна оснащены двойным тепловым остеклением квартира сдается мебели оборудована электроприборами установлены кондиционеры идеальное тихое место центре города цена снижена per month plus deposit\n",
      "[0.999206]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# serialize model to JSON\r\n",
    "\r\n",
    "model_path = conf.model_path\r\n",
    "weights_path = conf.weights_path\r\n",
    "\r\n",
    "model_json = model.to_json()\r\n",
    "\r\n",
    "with open(model_path, \"w\") as json_file:\r\n",
    "    json_file.write(model_json)\r\n",
    "# serialize weights to TF\r\n",
    "model.save_weights(weights_path)\r\n",
    "print(\"Saved model to disk\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "a= [{'name': 'Homer', 'age': 39}, {'name': 'Bart', 'age': 10}]\r\n",
    "newlist = sorted(a, key=lambda d: d['age']) \r\n",
    "print(newlist)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'name': 'Bart', 'age': 10}, {'name': 'Homer', 'age': 39}]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('pythonProject': conda)"
  },
  "interpreter": {
   "hash": "b5ed7aac63ba26b6cc13f3466962b87b151feb8ba9e841efa9abe3bad9164d9f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}